# ğŸ—“ï¸ Plan de travail â€“ Projet GuinÃ©eLex (Scraping & Structuration des donnÃ©es)

## ğŸ“ PÃ©riode : JEUDI â€“ Samedi jours de travail en duo

## ğŸ¯ Objectif principal :
Constituer un dataset complet, propre et structurÃ© des textes juridiques officiels de la GuinÃ©e (2020â€“2025), Ã  partir des sites du SGG et du Journal Officiel.

---

## ğŸ§  RÃ©partition de lâ€™Ã©quipe

| PrÃ©nom        | RÃ´le                               |
|---------------|------------------------------------|
| Foula         | Dev Web & Mobile â€“ scraping, structuration JSON, base |
| Mariame | Dev IA â€“ scraping, traitement du texte, prÃ©paration IA |

---

## ğŸ“¦ Contenus Ã  scraper

- ğŸ“˜ Lois (https://sgg.gov.gn/document/lois/{id})
- ğŸ“„ DÃ©crets
- ğŸ“‘ ArrÃªtÃ©s
- ğŸ“š Journaux Officiels (https://journal-officiel.sgg.gov.gn/JO/2025/...)

---

## ğŸ“‚ Structure de travail recommandÃ©e

GuineeLex/
â”œâ”€â”€ scraping/
â”‚ â”œâ”€â”€ pdfs_originaux/
â”‚ â”œâ”€â”€ textes_bruts/
â”‚ â”œâ”€â”€ nettoyÃ©s/
â”‚ â””â”€â”€ json_structurÃ©s/
â”œâ”€â”€ scripts/
â”œâ”€â”€ data/
â””â”€â”€ ai/

yaml
Copy
Edit



## ğŸ—“ï¸ Planning dÃ©taillÃ© sur 4 jours

### ğŸ”¹ Jeudi â€“ Recensement & tÃ©lÃ©chargement

- Lister les documents Ã  rÃ©cupÃ©rer (lois, JO, etc.)
- RÃ©partir les plages dâ€™URL Ã  parcourir (ex: lois/1 Ã  200 pour Foula, 201 Ã  400 pour [Nom])
- Lancer le tÃ©lÃ©chargement automatique (ou semi-auto) des fichiers PDF
- Nommer et ranger les fichiers dans `pdfs_originaux/`

âœ… RÃ©sultat : dossier `pdfs_originaux/` rempli et bien structurÃ©.

---

### ğŸ”¹ Vendredi â€“ Extraction du texte brut

- Extraire le texte de chaque PDF avec `PyMuPDF` ou `Tesseract`
- Supprimer les entÃªtes/pages inutiles
- Stocker chaque version brute dans `textes_bruts/`

âœ… RÃ©sultat : dossier `textes_bruts/` rempli de fichiers `.txt` lisibles.

---

### ğŸ”¹ Samedi â€“ Structuration des textes

- Analyser chaque fichier pour identifier les titres des textes (Loi, DÃ©cret, etc.)
- DÃ©couper et organiser chaque texte en format JSON :
```json
{
  "type": "Loi",
  "titre": "...",
  "date": "...",
  "numero": "...",
  "contenu": "..."
}
Regrouper les fichiers JSON dans json_structurÃ©s/

GÃ©nÃ©rer un fichier global dataset_juridique.json

âœ… RÃ©sultat : JSON propre et prÃªt Ã  Ãªtre utilisÃ© cÃ´tÃ© app et IA.

ğŸ”¹ Jour 4 â€“ Validation & enrichissement
VÃ©rification manuelle de lâ€™exactitude des textes extraits

Ajout de champs comme rÃ©sumÃ©, thÃ¨me, mots-clÃ©s, etc. (optionnel)

PrÃ©parer les fichiers dâ€™entrÃ©e pour les modÃ¨les IA

âœ… RÃ©sultat : dataset validÃ©, enrichi et prÃªt pour lâ€™application.

ğŸ“Œ Suivi de progression
TÃ¢che	                           Foula Mariame  	             Statut                             	
RÃ©cupÃ©ration des URLs / IDs lois	âœ…	âœ…	                 En cours
TÃ©lÃ©chargement des PDF	            âœ…	âœ…	                  Ã€ faire
Extraction du texte brut			                            Ã€ faire
Structuration JSON			                                    Ã€ faire
Nettoyage final			                                        Ã€ faire

ğŸ§  Notes importantes
Le scraping doit rester respectueux (Ã©viter de spammer le serveur)

Ne jamais pousser de PDF lourd ou .env dans le repo Git

Utiliser README.md pour documenter chaque Ã©tape ou dossier

Se synchroniser quotidiennement sur les points de blocage